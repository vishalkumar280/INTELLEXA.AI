{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**FINAL WITH GEN AI**"
      ],
      "metadata": {
        "id": "8F_hFO0FHXKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EVDAbk4fuyGY"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi uvicorn beautifulsoup4 requests sentence-transformers faiss-cpu transformers pyngrok nest-asyncio -q\n",
        "!pip install fastapi[all] -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import HTMLResponse, FileResponse"
      ],
      "metadata": {
        "id": "dzBe0zc-cXxl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply nest_asyncio for Jupyter/Colab environments\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Allow CORS for all origins\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Load the SentenceTransformer model for creating embeddings\n",
        "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Load the Hugging Face generative model pipeline (e.g., GPT-2 or similar)\n",
        "generative_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "\n",
        "# Test Hugging Face text generation\n",
        "test_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "test_output = test_model(\"This is a test.\", max_length=100)\n",
        "print(test_output)\n",
        "\n",
        "\n",
        "# In-memory FAISS index\n",
        "faiss_index = None\n",
        "stored_sentences = []\n",
        "SCRAPED_TEXT_FILE = \"/content/scraped_text.txt\"  # File to store scraped text\n",
        "\n",
        "# Define request models for FastAPI\n",
        "class LoadDataRequest(BaseModel):\n",
        "    url: str\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    query: str\n",
        "\n",
        "# Function to scrape Wikipedia content\n",
        "def extract_wikipedia_data(url: str) -> str:\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Failed to load page, status code: {response.status_code}\")\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    paragraphs = soup.find_all('p')\n",
        "    text = \" \".join([para.get_text() for para in paragraphs])\n",
        "\n",
        "    # Save the scraped text to a file\n",
        "    with open(SCRAPED_TEXT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Function to load text from file (if available)\n",
        "def load_text_from_file() -> str:\n",
        "    if os.path.exists(SCRAPED_TEXT_FILE):\n",
        "        with open(SCRAPED_TEXT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "            return f.read()\n",
        "    return None\n",
        "\n",
        "# Function to embed text and load it into FAISS\n",
        "def embed_and_store_text(text: str):\n",
        "    global faiss_index, stored_sentences\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = text.split(\". \")\n",
        "    embeddings = embedding_model.encode(sentences)\n",
        "\n",
        "    # Initialize FAISS index with cosine similarity\n",
        "    faiss_index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "    faiss.normalize_L2(embeddings)  # Normalize to use cosine similarity\n",
        "    faiss_index.add(np.array(embeddings).astype(\"float32\"))\n",
        "\n",
        "    stored_sentences = sentences\n",
        "\n",
        "# FastAPI endpoint to load data from Wikipedia and store embeddings in FAISS\n",
        "@app.post(\"/load\")\n",
        "def load_data(request: LoadDataRequest):\n",
        "    try:\n",
        "        # Step 1: Scrape Wikipedia data (always fetch new data)\n",
        "        content = extract_wikipedia_data(request.url)\n",
        "\n",
        "        # Step 2: Embed the text and store embeddings in FAISS\n",
        "        embed_and_store_text(content)\n",
        "\n",
        "        return {\"message\": \"Data loaded successfully\", \"total_sentences\": len(stored_sentences)}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# FastAPI endpoint to query the vector database and generate a response using a generative AI model\n",
        "@app.post(\"/query\")\n",
        "def query_data(request: QueryRequest):\n",
        "    try:\n",
        "        if faiss_index is None or faiss_index.ntotal == 0:\n",
        "            raise HTTPException(status_code=400, detail=\"FAISS index is not loaded with data\")\n",
        "\n",
        "        # Step 1: Embed the user query\n",
        "        query_embedding = embedding_model.encode([request.query])[0].astype(\"float32\")\n",
        "        print(\"Query Embedding Shape:\", query_embedding.shape)\n",
        "\n",
        "        # Step 2: Search for the top 3 most relevant sentences in FAISS\n",
        "        distances, indices = faiss_index.search(np.array([query_embedding]), k=3)\n",
        "        print(\"Distances:\", distances)\n",
        "        print(\"Indices:\", indices)\n",
        "\n",
        "        best_sentences = [stored_sentences[i] for i in indices[0]]\n",
        "        print(\"Best Matching Sentences:\", best_sentences)\n",
        "\n",
        "        # Step 3: Combine the retrieved sentences into a prompt for the generative AI model\n",
        "        # Limit to the first 2 sentences to reduce the length of the prompt\n",
        "        prompt = \" \".join(best_sentences[:2]) + f\" Based on this, answer the question: {request.query}\"\n",
        "        print(\"Prompt:\", prompt)\n",
        "\n",
        "        # Step 4: Generate a response using the generative AI model with max_new_tokens and truncation\n",
        "        generated_response = generative_model(\n",
        "            prompt,\n",
        "            max_new_tokens=50,  # Adjust this value for how long the response should be\n",
        "            truncation=True,  # Truncate if the input is too long\n",
        "        )[0]['generated_text']\n",
        "        print(\"Generated Response:\", generated_response)\n",
        "\n",
        "        # Return the AI-generated answer along with the best match sentences\n",
        "        return {\n",
        "            \"query\": request.query,\n",
        "            \"best_match_sentences\": best_sentences,\n",
        "            \"generated_answer\": generated_response\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "\n",
        "# Authenticate Ngrok with your authtoken\n",
        "ngrok_auth_token = '2mt1V0s487izXCkFecJdYcO5ucZ_2C6GTWT3XsGEYAP1F7MRM'  # Replace with your actual ngrok authtoken\n",
        "!ngrok authtoken {ngrok_auth_token}\n",
        "\n",
        "# Start ngrok tunnel to expose the local FastAPI app to the internet\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "# Serve the static background image\n",
        "@app.get(\"/background\")\n",
        "async def get_background():\n",
        "    return FileResponse(\"/content/Blue Futuristic Artificial Intelligence Presentation (3).jpg\")  # Adjust the path accordingly\n",
        "html_code = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>INTELLEXA</title>\n",
        "\n",
        "    <!-- Google Fonts -->\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap\" rel=\"stylesheet\">\n",
        "    <style>\n",
        "        /* General Page Styling */\n",
        "        body {\n",
        "            font-family: 'Roboto', sans-serif;\n",
        "            background: url('/background') no-repeat center center fixed;\n",
        "            background-size: cover;\n",
        "            color: #ffffff;\n",
        "            text-align: center;\n",
        "            min-height: 100vh;\n",
        "            display: flex;\n",
        "            justify-content: center;\n",
        "            align-items: center;\n",
        "            flex-direction: column;\n",
        "            margin: 0;\n",
        "        }\n",
        "\n",
        "        .content-wrapper {\n",
        "            display: flex;\n",
        "            flex-direction: column;\n",
        "            justify-content: flex-start;\n",
        "            align-items: flex-end;\n",
        "            text-align: right;\n",
        "            width: 100%;\n",
        "            max-width: 800px;\n",
        "            margin: 0 auto;\n",
        "            position: relative;\n",
        "            top: 150px; /* Moves the content downward */\n",
        "            left: 150px; /* Moves the content rightward */\n",
        "        }\n",
        "\n",
        "        /* Input container for aligning text box and button */\n",
        "        .input-container {\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            margin: 10px 0;\n",
        "            width: 100%;\n",
        "            justify-content: flex-end;\n",
        "        }\n",
        "\n",
        "        input[type=\"text\"] {\n",
        "            padding: 15px;\n",
        "            margin: 10px 0;\n",
        "            border-radius: 8px;\n",
        "            border: 2px solid white;\n",
        "            width: 100%;\n",
        "            max-width: 400px;\n",
        "            font-size: 1.1em;\n",
        "            background-color: rgba(255, 255, 255, 0.05);\n",
        "            color: #ffffff;\n",
        "            outline: none;\n",
        "        }\n",
        "\n",
        "        input[type=\"text\"]::placeholder {\n",
        "            color: rgba(240, 240, 240, 0.8);\n",
        "        }\n",
        "\n",
        "        button {\n",
        "            background-color: #007bff;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 5px;\n",
        "            padding: 15px 30px;\n",
        "            cursor: pointer;\n",
        "            font-weight: normal;\n",
        "            font-size: 1em;\n",
        "            margin-left: 10px; /* Space between the input field and the button */\n",
        "            transition: background-color 0.3s, transform 0.3s;\n",
        "        }\n",
        "\n",
        "        button:hover {\n",
        "            background-color: #0056b3;\n",
        "        }\n",
        "\n",
        "        button:active {\n",
        "            transform: scale(0.95);\n",
        "        }\n",
        "\n",
        "        #loadResult, #questionResult {\n",
        "            margin-top: 20px;\n",
        "            font-size: 1.1em;\n",
        "            color: #ffffff;\n",
        "            text-align: right;\n",
        "            font-family: 'Roboto', sans-serif;\n",
        "        }\n",
        "\n",
        "        #answerResult {\n",
        "            background-color: rgba(0, 0, 0, 0.6);\n",
        "            color: #ffffff;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            margin-top: 20px;\n",
        "            text-align: left;\n",
        "            line-height: 1.5;\n",
        "            max-width: 100%;\n",
        "            width: 600px;\n",
        "            max-height: 200px; /* Limit the height of the answer area */\n",
        "            overflow-y: auto; /* Enable vertical scroll */\n",
        "        }\n",
        "\n",
        "        #answerResult b {\n",
        "            color: #ffffff;\n",
        "        }\n",
        "\n",
        "        @media screen and (max-width: 768px) {\n",
        "            input[type=\"text\"] {\n",
        "                width: 90%;\n",
        "            }\n",
        "            #answerResult {\n",
        "                width: 90%;\n",
        "            }\n",
        "\n",
        "            .content-wrapper {\n",
        "                top: 100px;\n",
        "                left: 50px;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        /* Styling the scroll bar */\n",
        "        #answerResult::-webkit-scrollbar {\n",
        "            width: 8px;\n",
        "        }\n",
        "\n",
        "        #answerResult::-webkit-scrollbar-thumb {\n",
        "            background-color: rgba(255, 255, 255, 0.3); /* Customize the scrollbar */\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "    </style>\n",
        "    <script>\n",
        "        let isDataLoaded = false;  // Track if data has been loaded\n",
        "\n",
        "        async function loadData() {\n",
        "            const url = document.getElementById('inputField').value;\n",
        "            const loadResponse = await fetch('/load', {\n",
        "                method: 'POST',\n",
        "                headers: {\n",
        "                    'Content-Type': 'application/json'\n",
        "                },\n",
        "                body: JSON.stringify({ url })\n",
        "            });\n",
        "\n",
        "            if (loadResponse.ok) {\n",
        "                const loadData = await loadResponse.json();\n",
        "                document.getElementById('loadResult').textContent = \"DATA IS LOADED SUCCESSFULLY\";\n",
        "                isDataLoaded = true;  // Set flag indicating data is loaded\n",
        "            } else {\n",
        "                document.getElementById('loadResult').textContent = \"Failed to load data.\";\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function queryData() {\n",
        "            if (!isDataLoaded) {\n",
        "                alert(\"Please load data before querying!\");\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            const query = document.getElementById('inputFieldQuery').value;\n",
        "            const queryResponse = await fetch('/query', {\n",
        "                method: 'POST',\n",
        "                headers: {\n",
        "                    'Content-Type': 'application/json'\n",
        "                },\n",
        "                body: JSON.stringify({ query })\n",
        "            });\n",
        "\n",
        "            if (queryResponse.ok) {\n",
        "                const queryData = await queryResponse.json();\n",
        "                document.getElementById('questionResult').textContent = `Question: ${queryData.query}`;\n",
        "\n",
        "                // Display the best-matching sentences\n",
        "                let answersHtml = `Answer:<br>`;\n",
        "                queryData.best_match_sentences.forEach(sentence => {\n",
        "                    answersHtml += `<b>${sentence}</b><br>`;\n",
        "                });\n",
        "                document.getElementById('answerResult').innerHTML = answersHtml;\n",
        "            } else {\n",
        "                document.getElementById('questionResult').textContent = \"Error querying data.\";\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"content-wrapper\">\n",
        "        <div class=\"input-container\">\n",
        "            <input type=\"text\" id=\"inputField\" placeholder=\"Enter a Wikipedia URL\">\n",
        "            <button onclick=\"loadData()\">Load Data</button>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"loadResult\"></div>\n",
        "\n",
        "        <div class=\"input-container\">\n",
        "            <input type=\"text\" id=\"inputFieldQuery\" placeholder=\"Ask a question\">\n",
        "            <button onclick=\"queryData()\">Ask AI</button>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"questionResult\"></div>\n",
        "        <div id=\"answerResult\"></div>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "# FastAPI route to serve the HTML page\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "def get_html():\n",
        "    return HTMLResponse(content=html_code)\n",
        "\n",
        "# Start the FastAPI server\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zt-_cRpvhN3",
        "outputId": "ba49f99f-f0f1-4c31-e78c-80859f13cede"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'This is a test. The purpose of the test is to determine whether a device is capable of delivering a real-time message across the entire device. With this test, the user\\'s input must meet the given definition of a real-time message and receive information from a network message that represents the real-time message, such as the real-time time stamp when a request is placed. The user must only request information such as: \"message_to_reply.\" Then the user is presented with'}]\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Public URL: https://755b-34-168-45-3.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1147]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     2409:40f4:2052:1004:a48e:d6f6:7b67:d690:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2409:40f4:2052:1004:a48e:d6f6:7b67:d690:0 - \"GET /background HTTP/1.1\" 200 OK\n",
            "INFO:     2409:40f4:2052:1004:a48e:d6f6:7b67:d690:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:40f4:2052:1004:a48e:d6f6:7b67:d690:0 - \"POST /load HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Embedding Shape: (384,)\n",
            "Distances: [[0.74052584 0.730252   0.6656342 ]]\n",
            "Indices: [[6 5 9]]\n",
            "Best Matching Sentences: ['In January\\xa02019, active Python core developers elected a five-member Steering Council to lead the project.[45][46]\\n Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support.[47] Python\\xa03.0 was released on 3 December 2008, with many of its major features backported to Python\\xa02.6.x[48] and 2.7.x', 'Python\\xa02.7.18, released in 2020, was the last release of Python\\xa02.[36]\\n Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.[37][38][39][40]\\n Python was invented in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL,[42] capable of exception handling and interfacing with the Amoeba operating system.[12] Its implementation began in December\\xa01989.[43] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python\\'s \"benevolent dictator for life\" (BDFL), a title the Python community bestowed upon him to reflect his long-term commitment as the project\\'s chief decision-maker[44] (he has since come out of retirement and is self-titled \"BDFL-emeritus\")', 'While Python 2.7 and older is officially unsupported, a different unofficial Python implementation, PyPy, continues to support Python 2, i.e']\n",
            "Prompt: In January 2019, active Python core developers elected a five-member Steering Council to lead the project.[45][46]\n",
            " Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support.[47] Python 3.0 was released on 3 December 2008, with many of its major features backported to Python 2.6.x[48] and 2.7.x Python 2.7.18, released in 2020, was the last release of Python 2.[36]\n",
            " Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.[37][38][39][40]\n",
            " Python was invented in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL,[42] capable of exception handling and interfacing with the Amoeba operating system.[12] Its implementation began in December 1989.[43] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python's \"benevolent dictator for life\" (BDFL), a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker[44] (he has since come out of retirement and is self-titled \"BDFL-emeritus\") Based on this, answer the question: when python was released\n",
            "Generated Response: In January 2019, active Python core developers elected a five-member Steering Council to lead the project.[45][46]\n",
            " Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support.[47] Python 3.0 was released on 3 December 2008, with many of its major features backported to Python 2.6.x[48] and 2.7.x Python 2.7.18, released in 2020, was the last release of Python 2.[36]\n",
            " Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.[37][38][39][40]\n",
            " Python was invented in the late 1980s[41] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL,[42] capable of exception handling and interfacing with the Amoeba operating system.[12] Its implementation began in December 1989.[43] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python's \"benevolent dictator for life\" (BDFL), a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker[44] (he has since come out of retirement and is self-titled \"BDFL-emeritus\") Based on this, answer the question: when python was released, did you think it was worth spending at least as much time working for yourself as the major releases of Python?\n",
            "Python is open-source, but there must also be one important difference between what you already know about Python and what you know about\n",
            "INFO:     2409:40f4:2052:1004:a48e:d6f6:7b67:d690:0 - \"POST /query HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-10-15T13:56:40+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-81ea3e06-a491-4f3e-942a-d568a3a3cf5b acceptErr=\"failed to accept connection: Listener closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [1147]\n"
          ]
        }
      ]
    }
  ]
}